[
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1¬† Week 1 - Introduction to Remote Sensing",
    "section": "",
    "text": "2 Week 1 - Introduction to Remote Sensing"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "5¬† Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Chapter 4 - Atmospheric correction of optical imagery. (2020). In Advanced Remote Sensing (Second Edition, pp.¬†131‚Äì156). Elsevier Inc. https://doi.org/10.1016/B978-0-12-815826-5.00004-0\nDuke University; Spotting air pollution with satellites, better than ever before. (2020). In TB & Outbreaks Weekly (pp.¬†95-). NewsRx.\nGiardina, G., Macchiarulo, V., Foroughnia, F., Jones, J. N., Whitworth, M. R. Z., Voelker, B., Milillo, P., Penney, C., Adams, K., & Kijewski-Correa, T. (2023). Combining remote sensing techniques and field surveys for post-earthquake reconnaissance missions. Bulletin of Earthquake Engineering. https://doi.org/10.1007/s10518-023-01716-9\nGisgeography. ‚ÄúWhat is Remote Sensing? The Definitive Guide‚Äù Accessed 11 March 2024. https://gisgeography.com/remote-sensing-earth-observation-guide/#UseCases\nGuo, Y., Feng, N., Christopher, S. A., Kang, P., Zhan, F. B., & Hong, S. (2014). Satellite remote sensing of fine particulate matter (PM2.5) air quality over Beijing using MODIS. International Journal of Remote Sensing, 35(17), 6522‚Äì6544. https://doi.org/10.1080/01431161.2014.958245\nJenerowicz, A., Wierzbicki, D., & Kedzierski, M. (2023). Radiometric Correction with Topography Influence of Multispectral Imagery Obtained from Unmanned Aerial Vehicles. Remote Sensing (Basel, Switzerland), 15(8), 2059-. https://doi.org/10.3390/rs15082059\nLi, A., Wang, Q., Bian, J., & Lei, G. (2015). An improved physics-based model for topographic correction of landsat TM images. Remote Sensing (Basel, Switzerland), 7(5), 6296‚Äì6319. https://doi.org/10.3390/rs70506296\nLi, W., Shao, L., Wang, W., Li, H., Wang, X., Li, Y., Li, W., Jones, T., & Zhang, D. (2020). Air quality improvement in response to intensified control strategies in Beijing during 2013‚Äì2019. The Science of the Total Environment, 744, 140776‚Äì140776. https://doi.org/10.1016/j.scitotenv.2020.140776\nLiang, F., Xiao, Q., Huang, K., Yang, X., Liu, F., Li, J., Lu, X., Liu, Y., & Gu, D. (2020). The 17-y spatiotemporal trend of PM2.5 and its mortality burden in China. Proceedings of the National Academy of Sciences - PNAS, 117(41), 25601‚Äì25608. https://doi.org/10.1073/pnas.1919641117\nLiu, Y., Zhou, Y., & Lu, J. (2020). Exploring the relationship between air pollution and meteorological conditions in China under environmental governance. Scientific Reports, 10(1). https://doi.org/10.1038/s41598-020-71338-7\nLucas, R., Mueller, N., Siggins, A., Owers, C., Clewley, D., Bunting, P., Kooymans, C., Tissott, B., Lewis, B., Lymburner, L., & Metternicht, G. (2019). Land cover mapping using digital earth Australia. Data (Basel), 4(4), 143-. https://doi.org/10.3390/data4040143\nMa, Y., Zhang, W., Chen, X., Zhang, L., & Liu, Q. (2023). High Spatial Resolution Nighttime PM2.5 Datasets in the Beijing‚ÄìTianjin‚ÄìHebei Region from 2015 to 2021 Using VIIRS/DNB and Deep Learning Model. Remote Sensing (Basel, Switzerland), 15(17), 4271-. https://doi.org/10.3390/rs15174271\nMaji, K. J., Li, V. O., & Lam, J. C. (2020). Effects of China‚Äôs current Air Pollution Prevention and Control Action Plan on air pollution patterns, health risks and mortalities in Beijing 2014‚Äì2018. Chemosphere (Oxford), 260, 127572‚Äì127572. https://doi.org/10.1016/j.chemosphere.2020.127572\nMatricardi, E. A. T., Skole, D. L., Costa, O. B., Pedlowski, M. A., Samek, J. H., & Miguel, E. P. (2020). Long-term forest degradation surpasses deforestation in the Brazilian Amazon. Science (American Association for the Advancement of Science), 369(6509), 1378‚Äì1382. https://doi.org/10.1126/SCIENCE.ABB3021\nUNOOSA/UN-SPIDER. 2020. United Nations Office for Outer Space Affairs, UN-SPIDER, Knowledge Portal Space-based information for Disaster Management and Emergency Responsa. Accessed 20 March, 2024. https://www.un-spider.org/advisory-support/recommended-practices/recommended-practice-google-earth-engine-flood-mapping\nYang, X., Xiao, D., Bai, H., Tang, J., & Wang, W. (2022). Spatiotemporal Distributions of PM2.5 Concentrations in the Beijing‚ÄìTianjin‚ÄìHebei Region From 2013 to 2020. Frontiers in Environmental Science, 10. https://doi.org/10.3389/fenvs.2022.842237\nZhang, H., Wang, S., Hao, J., Wang, X., Wang, S., Chai, F., & Li, M. (2016). Air pollution and control action in Beijing. Journal of Cleaner Production, 112, 1519‚Äì1527. https://doi.org/10.1016/j.jclepro.2015.04.092\nZhu, X., Cai, F., Tian, J., & Williams, T. K. A. (2018). Spatiotemporal fusion of multisource remote sensing data: Literature survey, taxonomy, principles, applications, and future directions. Remote Sensing (Basel, Switzerland), 10(4), 527-. https://doi.org/10.3390/rs10040527"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ariel‚Äôs rs learning diary",
    "section": "",
    "text": "Personal Introductionüòä\nMy name is Ariel (Qianyu Ren), come from Shanghai, China. I am a very curious, enthusiastic and outgoing red-haired girl, so I named myself the same as a mermaid hhhhüßú‚Äç‚ôÄÔ∏èü§ó. I used to be an architect, and I‚Äôve been involved in nearly 20 actual projects, mainly mega public buildings, such as super high-rise office buildings, cultural and sports complexes, data center parks, etc., and 8 of them have already been completed and put into use.ü•∞ü•∞\n\n\n\nA few of the designs I have worked on (I have done special effects on the renderings).\n\n\nFrankly speaking, I am not the person who can always think out of the box, when I see my colleagues and classmates deeply love and enjoy designing buildings, I am very envious, because I need to rack my brains to design and create every day, so I feel drained after years of studying and working in architectural design (of course, this doesn‚Äôt affect my colleagues and teachers who recognise my achievements haha). I have come to realise that I am more of a science thinker, good at maths and passionate about analysing problems through a scientific and rational lens. In addition, throughout my career, I have recognised the limitations that come with being detached from technology and have developed a keen interest in cutting-edge technology and the use of data analysis to solve problems. This drove me to CASA to learn the most advanced technologies and methods and develop practical skills to find my true passion.\nI chose the Remote Sensing course because of my interest, and it will enable me to manipulate remotely sensed earth observation data in order to make informed decisions about environmental challenges around the world. It seems pretty cool doesn‚Äôt it, especially when a cute girl operates it. I also hope to use remote sensing in my dissertation to explore new ways of urban resilience and sustainability. I am grateful for the opportunity to be able to explore new areas. I hope to find a balance between my ideals and experiences to become an integrated, interdisciplinary person who can use my background and new skills to address the challenges facing cities today. This website is my learning diary on Remotely Sensing Cities and Environments, documenting my learning outcomes and reflections, and I hope you enjoy it too!"
  },
  {
    "objectID": "intro.html#summary",
    "href": "intro.html#summary",
    "title": "1¬† Week 1 - Introduction to Remote Sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\nIn my first remote sensing class, I stepped into a world where satellites and sensors act like high-tech scouts, constantly transmitting data about our planet. Seeing how these eyes in the sky capture the world as it is helps us understand everything from urban sprawl to retreating glaciers.\n\n\n\n\n\n\n\n\n\nHere‚Äôs what I learnt this week:\n\n1.1.1 Remote sensing\nGather information about the Earth‚Äôs surface through sensors mounted on satellites or aircraft, which provides information where there are no ground-based measurements.\n\n\n1.1.2 Types of sensors\n\nActive sensors\nThis type of sensor illuminates its target and then measure the reflected light. Imagine the flash of a camera. It brightens its target. Next, it captures the return light. This is the same principle of how active sensors work. They can pass through clouds and work in the dark, such as X-rays, radar (e.g., synthetic aperture radar (SAR), laser radar (LIDAR)), which are commonly used for topographic mapping and forest altitude measurements.\n\n\n\n\nDiagram of an active sensor. Source: Gisgeography.\n\n\n\nPassive sensors\nMeasure reflected light emitted from the sun. When sunlight reflects off the Earth‚Äôs surface, passive sensors capture that light (e.g., the human eye, cameras, and multispectral sensors such as LANDSAT and Sentinel). They capture images by sensing reflected sunlight in the electromagnetic spectrum, which are commonly used in water resource management, climate change monitoring and disaster response.\n\n\n\n\nDiagram of a passive sensor. Source: Gisgeography.\n\n\n\n\n1.1.3 Electromagnetic Waves (EW)\nEW are the core of remote sensing technology, capturing and analyzing energy reflected or emitted by the Earth to discern surface characteristics. This is based on how various materials absorb and reflect different electromagnetic spectrum bands, allowing the identification and classification of surface substances and phenomena through specific bands‚Äô reception. The figure below shows the different types of EV, which are arranged from longest to shortest wavelength. The longer the wavelength, the lower the frequency; and vice versa.\n\n\n\nDiagram of the Electromagnetic Spectrum. Source: NASA Science.\n\n\nIn addition, different wavelengths lead to different colour spectra, which is why we can see coloured images. For example, the blue colour of the sky is mainly due to the phenomenon of Rayleigh scattering in the atmosphere, which makes shorter wavelengths of blue light scatter more easily than longer wavelengths of light.\nAt sunrise or sunset there is much more atmosphere to pass through so more scattering occurs When the sun‚Äôs angle changes the blue light scatter doesn‚Äôt reach our eyes as the distance is increased. So longer wavelengths (e.g.reds and oranges) reach us.\n\n\n\nWhy the sky is blue. Source: Explaining Science.\n\n\n\n\n1.1.4 Resolution\nResolution is one of the most important attributes of satellite imagery and will vary depending on the orbit of the satellite and the design of the sensor. For any data set, there are three types of resolution that need to be considered:\n\nSpatial Resolution: governs how ‚Äúsharp‚Äù an image looks (MAXAR deliver clear, high spatial resolution images, but a limited spectral range)\nSpectral Resolution: the ability of the sensor to recognise finer wavelengths (Landsat and Sentinel-2 may have lower spatial resolution but detect a wider spectrum)\nTemporal Resolution: the frequency with which we can access new imagery\n\nThe Google Maps basemap provides a very high-resolution view of the globe free of charge, but it captures only a single moment in time, lacking a temporal aspect. This means if we‚Äôre interested in observing changes that occur over time, this basemap won‚Äôt be very helpful. The term ‚Äúrevisit rate‚Äù refers to the frequency at which a satellite returns to observe the same spot on Earth.\n\n\nVideo\nWith its duo of satellites, the Sentinel-2 mission can boast a revisit rate of every 5 days. Source: ESA.\n\n\nFor the other two, spatial resolution determines the smallest visible detail size, while spectral resolution refers to the range of detectable spectra or colors by a satellite. For example, using a high-resolution camera allows clear visibility of tiny details, similar to how high spatial resolution satellite images can reveal fine ground features.\n\n\n\nThe same image at different spatial resolutions: (from left to right) 1 m, 10 m, and 30 m. Source: Coast Noaa.\n\n\nConversely, imagine having glasses that don‚Äôt enhance clarity but allow seeing beyond the visible spectrum, like in infrared or ultraviolet. This capability, akin to high spectral resolution satellites, offers insights into unseen aspects such as plant health or material types.\nThe image below shows Gilette Stadium near Boston, and if we were to use only the naked eye we would think that all three green areas were grass, and would not be able to distinguish which was real grass and which was artificial plastic grass, but living plants strongly reflect parts of the spectrum of the sun‚Äôs radiation that we do not see (near-infrared). However, by looking at the NDVI overlay of the Sentinel-2 satellite image, the two patches of real grass in red can be clearly identified.\n\n\n\nVHR image of Gilette Stadium with Sentinel-2 derived NDVI overlay. Source: Oballinger.\n\n\nWhy not build a sensor that combines high spatial, spectral and temporal resolution? Because it is difficult to combine all of the required functions into a single remote sensor, researchers must make trade-offs, understand the types of data that are more important for the specific field. For example, high temporal resolution is critical when studying weather over time, while higher spectral or spatial resolution is more important when studying seasonal vegetation changes."
  },
  {
    "objectID": "index.html#personal-introduction",
    "href": "index.html#personal-introduction",
    "title": "Ariel‚Äôs RS learning diary",
    "section": "Personal Introductionüòä",
    "text": "Personal Introductionüòä\nMy name is Ariel (Qianyu Ren), come from Shanghai, China. I am a very curious, enthusiastic and outgoing red-haired girl, so I named myself the same as a mermaid hhhhüßú‚Äç‚ôÄÔ∏èü•∞. I used to be an architect, and I‚Äôve been involved in nearly 20 actual projects, mainly mega public buildings, such as super high-rise office buildings, cultural and sports complexes, data center parks, etc., and 8 of them have already been completed and put into use.\n\n\n\n\n\n\n\n\n\nFrankly speaking, I am not the person who can always think out of the box, so when I see my colleagues deeply love and enjoy designing buildings, I am very envious, because I need to rack my brains to create every day, so I feel drained after years of studying and working in architectural design (of course, this doesn‚Äôt affect my colleagues and leaders who recognise my achievements hhhh).\nI have come to realise that I, who was good at maths, passionate about analysing problems through a scientific and rational lens. In addition, throughout my career, I have also recognised the limitations that come with being detached from cutting-edge technology. This drove me to CASA to learn the most advanced technologies and develop practical skills to find my true passion.\nHere are some of the designs I have worked on (I have done special effects on the renderings).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs for why I chose the Remote Sensing Cities and Environments course, first because of my interest, it will enable me to manipulate remotely sensed earth observation data, it seems pretty cool doesn‚Äôt it? And I also hope to use remote sensing in my dissertation to explore new ways of urban resilience and sustainability. I am grateful for the opportunity to be able to explore new areas. I hope to find a balance between my ideals and experiences to become an integrated, interdisciplinary person. This website is my learning diary on RS, documenting my learning outcomes and reflections, I hope you enjoy it too!"
  },
  {
    "objectID": "personal-introduction.html",
    "href": "personal-introduction.html",
    "title": "Personal Introductionüòä",
    "section": "",
    "text": "My name is Ariel (Qianyu Ren), come from Shanghai, China. I am a very curious, enthusiastic and outgoing red-haired girl, so I named myself the same as a mermaid hhhhüßú‚Äç‚ôÄÔ∏èü•∞. I used to be an architect, and I‚Äôve been involved in nearly 20 actual projects, mainly mega public buildings, such as super high-rise office buildings, cultural and sports complexes, data center parks, etc., and 8 of them have already been completed and put into use.\n\n\n\n\n\n\n\n\n\nFrankly speaking, I am not the person who can always think out of the box, so when I see my colleagues deeply love and enjoy designing buildings, I am very envious, because I need to rack my brains to create every day, so I feel drained after years of studying and working in architectural design (of course, this doesn‚Äôt affect my colleagues and leaders who recognise my achievements hhhh).\nI have come to realise that I, who was good at maths, passionate about analysing problems through a scientific and rational lens. In addition, throughout my career, I have also recognised the limitations that come with being detached from cutting-edge technology. This drove me to CASA to learn the most advanced technologies and develop practical skills to find my true passion.\nHere are some of the designs I have worked on (I have done special effects on the renderings).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs for why I chose the Remote Sensing Cities and Environments course, first because of my interest, it will enable me to manipulate remotely sensed earth observation data, it seems pretty cool doesn‚Äôt it? And I also hope to use remote sensing in my dissertation to explore new ways of urban resilience and sustainability. I am grateful for the opportunity to be able to explore new areas. I hope to find a balance between my ideals and experiences to become an integrated, interdisciplinary person. This website is my learning diary on RS, documenting my learning outcomes and reflections, I hope you enjoy it too!"
  },
  {
    "objectID": "intro.html#application",
    "href": "intro.html#application",
    "title": "1¬† Week 1 - Introduction to Remote Sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\nAfter understanding the basic concepts of remote sensing and related terminology, I began to delve into its application areas, which help us solve many real-world problems.\n For example, in agriculture, NDVI (Normalised Vegetation Index) is a very useful tool derived from remote sensing. It measures the health of vegetation by comparing the reflectance of near-infrared light (reflected by plants) to red light (absorbed by plants). In this way, farmers can track crop health, manage resources more efficiently, and even predict yields.\n\n\n\nThe relationship between a plant‚Äôs health status and the gradual increase in NDVI value. Source: Cropin.\n\n\nAlso, using remote sensing, we can keep a close eye on active volcanoes, looking for any changes in their thermal profiles that might indicate an imminent eruption. This is critical in areas where volcanoes pose a risk to populations and infrastructure and where traditional observation methods are too dangerous.\n\n\n\nThe SAR interferogram displays May 2015 ground motion at Piton de la Fournaise, with each color fringe indicating about 3 cm of movement. Source: Sentinels Copernicus.\n\n\nAnother impressive application is disaster management. After an earthquake, it is crucial to assess the damage quickly. Satellites routinely monitoring Earth from space and delivering data to support rapid damage mapping offer a unique tool to aid disaster management. This helps rescuers know where they are most needed, saving precious time and lives.\n\n\n\nThe map, based on data from French Pl√©iades satellites, details the destruction in Morocco caused by the earthquake on 8 September 2023. Source: ESA.\n\n\nRemote sensing is truly an indispensable tool in our toolkit for effective management of the planet and its resources. I have to mention that the teacher mentioned a very interesting case study on illegal deforestation in Brazil, which aroused my great interest in GEE, and I am very much looking forward to it."
  },
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "1¬† Week 1 - Introduction to Remote Sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\nIn my first remote sensing class, I stepped into a world where satellites and sensors act like high-tech scouts, constantly transmitting data about our planet. Seeing how these eyes in the sky capture the world as it is helps us understand everything from urban sprawl to retreating glaciers.\n\n\n\n\n\n\n\n\n\nHere‚Äôs what I learnt this week:\n\n1.1.1 Remote sensing\nGather information about the Earth‚Äôs surface through sensors mounted on satellites or aircraft, which provides information where there are no ground-based measurements.\n\n\n1.1.2 Types of sensors\n\nActive sensors\nEmit electro-entropic magnetic (EM) waves and receive reflected signals, can pass through clouds and work in the dark, such as X-rays, radar (e.g., synthetic aperture radar (SAR), laser radar (LIDAR)), which are commonly used for topographic mapping and forest altitude measurements.\nPassive sensors\nRely on the energy radiated by the sun or the earth itself and do not emit any signals, but only receive the energy reflected back from the light emitted by the sun, (e.g., the human eye, cameras, and multispectral sensors such as those from the LANDSAT series of satellites), which are commonly used in water resource management, climate change monitoring and disaster response.\n\n\n\n\nDiagram of a passive sensor versus an active sensor. Source: NASA Applied Sciences Fundamentals of Remote Sensing.\n\n\n\n\n1.1.3 Electromagnetic waves\nElectromagnetic waves are the core of remote sensing technology, which obtains information about the characteristics of the Earth‚Äôs surface by capturing and analysing electromagnetic waves reflected or radiated back from the Earth‚Äôs surface. Specifically, different substances and surfaces absorb and reflect various bands of electromagnetic waves in different ways, and remote sensing equipment takes advantage of this property to identify and classify surface materials and phenomena by receiving electromagnetic waves in specific bands. The figure below shows the different types of electromagnetic waves, which are arranged from longest to shortest wavelength. The longer the wavelength, the lower the frequency; and vice versa.\n\n\n\nDiagram of the Electromagnetic Spectrum. Source: NASA Science.\n\n\nIn addition, different wavelengths lead to different colour spectra, which is why we can see coloured images. For example, the blue colour of the sky is mainly due to the phenomenon of Rayleigh scattering in the atmosphere, which makes shorter wavelengths of blue light scatter more easily than longer wavelengths of light (e.g., red, orange, yellow).\nAt sunrise or sunset there is much more atmosphere to pass through so more scattering occurs When the sun‚Äôs angle changes the blue light scatter doesn‚Äôt reach our eyes as the distance is increased = so longer wavelengths reach us= reds and oranges.\n\n\n\nWhy the sky is blue. Source: Explaining Science.\n\n\n\n\n1.1.4 Resolution\nResolution plays an important role in the use of sensor data and will vary depending on the orbit of the satellite and the design of the sensor. For any data set, there are four types of resolution that need to be considered:\n\nRadiometric Resolution: the amount of information in each pixel; the higher the radiometric resolution, the more values of information are stored\nSpatial Resolution: the size of the smallest recognisable object in the image\nSpectral Resolution: the ability of the sensor to recognise finer wavelengths - the narrower the range of wavelengths are, the finer the spectral resolution\nTemporal Resolution: the time it takes for the satellite to time it takes to complete an orbit and revisit the same observation area\n\n\n\n\nThe same image at different spatial resolutions: (from left to right) 1 m, 10 m, and 30 m. Source: Coast Noaa.\n\n\nWhy not build a sensor that combines high spatial, spectral and temporal resolution? Because it is difficult to combine all of the required functions into a single remote sensor, researchers must make trade-offs, understand the types of data that are more important for the specific field. For example, high temporal resolution is critical when studying weather over time, while higher spectral or spatial resolution is more important when studying seasonal vegetation changes."
  },
  {
    "objectID": "week1.html#application",
    "href": "week1.html#application",
    "title": "1¬† Week 1 - Introduction to Remote Sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\nAfter understanding the basic concepts of remote sensing and related terminology, I began to delve into its application areas, which help us solve many real-world problems.\n\n\n\nRemote sensing application diagram made by myself.\n\n\nFor example, using remote sensing, we can keep a close eye on active volcanoes, looking for any changes in their thermal profiles that might indicate an imminent eruption. This is critical in areas where volcanoes pose a risk to populations and infrastructure and where traditional observation methods are too dangerous.\n\n\n\n\n\n\n\n\n\n\n\n\nBezymianny Volcano image, acquired on May 29, 2022, by the Operational Land Imager (OLI) on Landsat 8. Source: NASA Earth Observatory image by Joshua Stevens.\n\n\nAnother impressive application is disaster management. After an earthquake, it is crucial to assess the damage quickly. The use of remote sensing, particularly object-based image classification and change detection, can speed up this process by providing an accurate damage assessment from above. This helps rescuers know where they are most needed, saving precious time and lives.\n\n\n\nClassification of building damage, Source: Giorgia et al..\n\n\nIn agriculture, NDVI (Normalised Vegetation Index) is a very useful tool derived from remote sensing. It measures the health of vegetation by comparing the reflectance of near-infrared light (reflected by plants) to red light (absorbed by plants). In this way, farmers can track crop health, manage resources more efficiently, and even predict yields. This only scratches the surface. Remote sensing helps monitor the environment and biodiversity, plan urban and rural infrastructure, manage natural resources, and much more. It is truly an indispensable tool in our toolkit for effective management of the planet and its resources.\n\n\n\nThe relationship between a plant‚Äôs health status and the gradual increase in NDVI value. Source: Cropin.\n\n\nI have to mention that the teacher mentioned a very interesting case study on illegal deforestation in Brazil, which aroused my great interest in GEE, and I am very much looking forward to it."
  },
  {
    "objectID": "week2.html#summary",
    "href": "week2.html#summary",
    "title": "2¬† Week 1 - Introduction to Remote Sensing",
    "section": "2.1 Summary",
    "text": "2.1 Summary\nIn my first remote sensing class, I stepped into a world where satellites and sensors act like high-tech scouts, constantly transmitting data about our planet. Seeing how these eyes in the sky capture the world as it is helps us understand everything from urban sprawl to retreating glaciers.\n\n\n\n\n\n\n\n\n\nHere‚Äôs what I learnt this week:\n\n2.1.1 Remote sensing\nGather information about the Earth‚Äôs surface through sensors mounted on satellites or aircraft.\n\n\n2.1.2 Types of sensors\n\nActive sensors\nEmit electro-entropic magnetic (EM) waves and receive reflected signals, can pass through clouds and work in the dark, such as X-rays, radar (e.g., synthetic aperture radar (SAR), laser radar (LIDAR)), which are commonly used for topographic mapping and forest altitude measurements.\nPassive sensors\nRely on the energy radiated by the sun or the earth itself and do not emit any signals, but only receive the energy reflected back from the light emitted by the sun, (e.g., the human eye, cameras, and multispectral sensors such as those from the LANDSAT series of satellites), which are commonly used in water resource management, climate change monitoring and disaster response.\n\n\n\n\nDiagram of a passive sensor versus an active sensor. Credit: NASA Applied Sciences Remote Sensing Training Program.\n\n\n\n\n2.1.3 Electromagnetic waves\nElectromagnetic waves are the core of remote sensing technology, which obtains information about the characteristics of the Earth‚Äôs surface by capturing and analysing electromagnetic waves reflected or radiated back from the Earth‚Äôs surface. Specifically, different substances and surfaces absorb and reflect various bands of electromagnetic waves in different ways, and remote sensing equipment takes advantage of this property to identify and classify surface materials and phenomena by receiving electromagnetic waves in specific bands. The figure below shows the different types of electromagnetic waves, which are arranged from longest to shortest wavelength. The longer the wavelength, the lower the frequency; and vice versa.\n\n\n\nDiagram of the Electromagnetic Spectrum. Credit: NASA Science.\n\n\nIn addition, different wavelengths lead to different colour spectra, which is why we can see coloured images. For example, the blue colour of the sky is mainly due to the phenomenon of Rayleigh scattering in the atmosphere, which makes shorter wavelengths of blue light scatter more easily than longer wavelengths of light (e.g., red, orange, yellow).\n\n\n2.1.4 Resolution\nResolution plays an important role in the use of sensor data and will vary depending on the orbit of the satellite and the design of the sensor. For any data set, there are four types of resolution that need to be considered:\n\nRadiometric Resolution: the amount of information in each pixel; the higher the radiometric resolution, the more values of information are stored\nSpatial Resolution: the size of the smallest recognisable object in the image\nSpectral Resolution: the ability of the sensor to recognise finer wavelengths - the narrower the range of wavelengths are, the finer the spectral resolution\nTemporal Resolution: the time it takes for the satellite to time it takes to complete an orbit and revisit the same observation area\n\nWhy not build a sensor that combines high spatial, spectral and temporal resolution? Because it is difficult to combine all of the required functions into a single remote sensor, researchers must make trade-offs, understand the types of data that are more important for the specific field. For example, high temporal resolution is critical when studying weather over time, while higher spectral or spatial resolution is more important when studying seasonal vegetation changes."
  },
  {
    "objectID": "week2.html#application",
    "href": "week2.html#application",
    "title": "2¬† Week 1 - Introduction to Remote Sensing",
    "section": "2.2 Application",
    "text": "2.2 Application\nAfter understanding the basic concepts of remote sensing and related terminology, I began to delve into its application areas, which help us solve many real-world problems.\nFor example, using remote sensing, we can keep a close eye on active volcanoes, looking for any changes in their thermal profiles that might indicate an imminent eruption. This is critical in areas where volcanoes pose a risk to populations and infrastructure and where traditional observation methods are too dangerous.\nAnother impressive application is disaster management. After an earthquake, it is crucial to assess the damage quickly. The use of remote sensing, particularly object-based image classification and change detection, can speed up this process by providing an accurate damage assessment from above. This helps rescuers know where they are most needed, saving precious time and lives.\nIn agriculture, NDVI (Normalised Vegetation Index) is a very useful tool derived from remote sensing. It measures the health of vegetation by comparing the reflectance of near-infrared light (reflected by plants) to red light (absorbed by plants). In this way, farmers can track crop health, manage resources more efficiently, and even predict yields. This only scratches the surface. Remote sensing helps monitor the environment and biodiversity, plan urban and rural infrastructure, manage natural resources, and much more. It is truly an indispensable tool in our toolkit for effective management of the planet and its resources.\nI have to mention that my teacher mentioned a very interesting case study about illegal deforestation in Brazil, which has piqued my great interest in GEE, which I am really looking forward to."
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1¬† Week 1 - Introduction to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nMy first remote sensing class took me on an exciting journey as we began to learn how to use technology to view our planet from above, opening a window to a new world perspective, allowing me to see the changes happening around the world without leaving home. The possibilities are endless, from how to track environmental changes, such as the shrinking of glaciers or the growth of cities, and how it can aid in disaster response, giving me a foundational understanding of remote sensing technology.\nAlthough the technology of remote sensing is interesting, it is indeed complex. The course was filled with mind-boggling new terms and concepts that piqued my curiosity. I had a lot to learn about what types of data could be captured, how to analyze it, and the different ways to apply it. In an era of increasing climate change, being able to decipher and use this data for urban planning or disaster response is critical. Although the complexity of remote sensing can feel like a mountain to climb, I believe that with time and practical experience, I will no longer be afraid of it and it will prepare me to make a tangible difference in the world.üòä"
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "3¬† Week 3 - Corrections and Image Enhancements",
    "section": "3.1 Summary",
    "text": "3.1 Summary\nThis remote sensing lesson covers methods of acquiring and processing remote sensing data and how to apply this data to study cities and the environment. It is mainly divided into two parts: (1) corrections (2) data joining and enhancement.\n\n3.1.1 Corrections\nVarious errors that may exist in remote sensing images (e.g., due to factors such as sensors, atmosphere, terrain, etc.) and how to correct them through different techniques.\n\n\n3.1.2 Geometric Correction\nHow can image distortions caused by factors such as shooting angle, terrain, wind speed (if data is obtained from an airplane), and the Earth‚Äôs rotation be addressed? The purpose of geometric correction is to match images with ground control points or other known reference data to ensure spatial accuracy of the images.\n ¬† ¬† ¬† ¬† \nGeometric correction process. Source: Catalyst Earth\n\n\n3.1.3 Atmospheric Correction\nFocuses on eliminating the effects of the atmosphere on satellite or aerial image data to more accurately reflect the actual reflectivity or brightness value of the surface.\nAs solar radiation passes through the atmosphere to reach the Earth‚Äôs surface, and then reflects back to the sensor, it is scattered and absorbed by gases, water droplets, and particulate matter in the atmosphere. This alters the radiation signal that reaches the sensor.\n\nRelative correction, such as DOS and Pseudo-Invariant Features, uses internal image references for correction and is suitable when atmospheric parameters are lacking.\nAbsolute correction, applies atmospheric models like MODTRAN for direct correction.\n\n\n\n\nGF-1 WFV data true color composite map (left: before atmospheric correction; right: after atmospheric correction). Source: Chapter 4 - Atmospheric correction of optical imagery, 2020\n\n\n\n\n3.1.4 Orthorectification/Topographic Correction\nCorrect image distortions caused by terrain undulations. Specifically, we can use a Digital Elevation Model (DEM) to convert remote sensing images from perspective to orthographic projection corrects distortions from terrain variations, such as mountains and buildings. This alignment results in more accurate positioning, clearer textures, and sharper boundaries in images (Li et al., 2015).\n\n\n3.1.5 Radiometric Correction\nInvolves converting digital image data captured by sensors into true ground reflectance values. This process corrects for sensor system errors and atmospheric condition changes and solar irradiance variations. For example, slopes facing the sun and those in shadow may reflect sunlight in completely different ways. This difference can cause these areas to appear with varying brightness or colors in images, which may then be mistakenly classified into different categories (Jenerowicz et al., 2023).\n\n\n3.1.6 Data Joining and Image Enhancements\nThis part gave me an understanding of how image data from different points in time or from different sensors can be effectively joined, and how image quality and visualisation of information can be improved through image enhancement techniques.\nSpecifically, image enhancement methods include contrast enhancement, spatial enhancement (such as filtering and edge enhancement), Principal Component Analysis (PCA) for dimension reduction, texture analysis for spatial variation, and image fusion techniques to combine data from multiple sources or sensors and so on.\n\n\n\nInput and output of spatiotemporal data fusion. Source: Zhu et al., 2018\n\n\nThe above image demonstrates a technique for image fusion. On the left, there is a sequence of dense, coarse images with low resolution but high acquisition frequency. In the middle, there are sparse, fine images with high resolution but lower frequency of acquisition. Through spatiotemporal data fusion, a high-resolution and information-rich fine image is synthesized (on the right), effectively combining the advantages of both image types.\n\n\n\nRemote sensing image using false color synthesis technique. Source: Wordpress\n\n\nThis image shows remote sensing imagery enhanced by false-color compositing, a method to highlight specific land features by assigning different spectral bands to RGB colors. It illustrates three different band combinations emphasizing vegetation (6,5,2), buildings (7,6,4), and a combination for vegetation (5,4,3) and distinguishing land/water (5,6,4). This technique not only improves visual perception but also aids in analyzing and identifying various land cover types."
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "3¬† Week 3 - Corrections",
    "section": "3.2 Application",
    "text": "3.2 Application\nAfter understanding the basic concepts of remote sensing and related terminology, I began to delve into its application areas, which help us solve many real-world problems."
  },
  {
    "objectID": "intro.html#reflection",
    "href": "intro.html#reflection",
    "title": "1¬† Week 1 - Introduction to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nMy first remote sensing class took me on an exciting journey as we began to learn how to use technology to view our planet from above, allowing me to see the changes happening around the world without leaving home. The possibilities are endless, from how to track environmental changes, such as the shrinking of glaciers or the growth of cities, and how it can aid in disaster response, now I have a foundational understanding of remote sensing technology.\nAlthough the technology of remote sensing is interesting, it is indeed complex. The course was filled with mind-boggling new terms, I had a lot to learn about what types of data could be captured, how to analyze it, and the different ways to apply it. In an era of increasing climate change, being able to decipher and use this data for urban planning or disaster response is critical. Although the complexity of remote sensing can feel like a mountain to climb, I believe that with time and practical experience, I will no longer be afraid of it and it will prepare me to make a tangible difference in the world.üí™"
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2¬† Week 2 - Presentation of Sentinel-1",
    "section": "",
    "text": "To view this presentation in full screen, please click here."
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3¬† Week 3 - Corrections",
    "section": "",
    "text": "4 I have to mention that my teacher mentioned a very interesting case study about illegal deforestation in Brazil, which has piqued my great interest in GEE, which I am really looking forward to."
  },
  {
    "objectID": "week3.html#summary-1",
    "href": "week3.html#summary-1",
    "title": "3¬† Week 3 - Corrections",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nThis remote sensing lesson covers methods of acquiring and processing remote sensing data and how to apply this data to study cities and the environment. It is mainly divided into two parts: (1) corrections (2) data joining and enhancement.\n\n\n\n\n\n\n\n\n\n\n5.1.1 Corrections\nVarious errors that may exist in remote sensing images (e.g., due to factors such as sensors, atmosphere, terrain, etc.) and how to correct them through different techniques.\n\nGeometric correction: mainly focuses on the coordinate system and distortion of the image\nAtmospheric correction: involves eliminating the effects of atmospheric scattering and absorption\nOrthorectification/topographic correction: removes the deformation caused by terrain\nRadiometric correction: focuses on how to convert the digital value of the image into Spectral radiance with actual physical meaning\n\nVarious correction methods required to preprocess remote sensing data. These include\n\n\n\nDiagram of a passive sensor versus an active sensor. Credit: NASA Applied Sciences Remote Sensing Training Program.\n\n\n\n\n5.1.2 Resolution\nResolution plays an important role in the use of sensor data and will vary depending on the orbit of the satellite and the design of the sensor. For any data set, there are four types of resolution that need to be considered:\n\nRadiometric Resolution: the amount of information in each pixel; the higher the radiometric resolution, the more values of information are stored\nSpatial Resolution: the size of the smallest recognisable object in the image\nSpectral Resolution: the ability of the sensor to recognise finer wavelengths - the narrower the range of wavelengths are, the finer the spectral resolution\nTemporal Resolution: the time it takes for the satellite to time it takes to complete an orbit and revisit the same observation area\n\nWhy not build a sensor that combines high spatial, spectral and temporal resolution? Because it is difficult to combine all of the required functions into a single remote sensor, researchers must make trade-offs, understand the types of data that are more important for the specific field. For example, high temporal resolution is critical when studying weather over time, while higher spectral or spatial resolution is more important when studying seasonal vegetation changes."
  },
  {
    "objectID": "week3.html#application-1",
    "href": "week3.html#application-1",
    "title": "3¬† Week 3 - Corrections",
    "section": "5.2 Application",
    "text": "5.2 Application\nAfter understanding the basic concepts of remote sensing and related terminology, I began to delve into its application areas, which help us solve many real-world problems.\nFor example, using remote sensing, we can keep a close eye on active volcanoes, looking for any changes in their thermal profiles that might indicate an imminent eruption. This is critical in areas where volcanoes pose a risk to populations and infrastructure and where traditional observation methods are too dangerous.\nAnother impressive application is disaster management. After an earthquake, it is crucial to assess the damage quickly. The use of remote sensing, particularly object-based image classification and change detection, can speed up this process by providing an accurate damage assessment from above. This helps rescuers know where they are most needed, saving precious time and lives.\nIn agriculture, NDVI (Normalised Vegetation Index) is a very useful tool derived from remote sensing. It measures the health of vegetation by comparing the reflectance of near-infrared light (reflected by plants) to red light (absorbed by plants). In this way, farmers can track crop health, manage resources more efficiently, and even predict yields. This only scratches the surface. Remote sensing helps monitor the environment and biodiversity, plan urban and rural infrastructure, manage natural resources, and much more. It is truly an indispensable tool in our toolkit for effective management of the planet and its resources.\nI have to mention that my teacher mentioned a very interesting case study about illegal deforestation in Brazil, which has piqued my great interest in GEE, which I am really looking forward to. &gt;&gt;&gt;&gt;&gt;&gt;&gt; c7cbe46a7a15f949d1595792616a2ae09174c676"
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "4¬† Week 2 - Presentation of Sentinel-1",
    "section": "",
    "text": "To view this presentation in full screen, please click here."
  },
  {
    "objectID": "week8.html",
    "href": "week8.html",
    "title": "6¬† Week 8 - Presentation of Sentinel-1",
    "section": "",
    "text": "To view this presentation in full screen, please click here."
  },
  {
    "objectID": "week3.html#applications",
    "href": "week3.html#applications",
    "title": "3¬† Week 3 - Corrections and Image Enhancements",
    "section": "3.2 Applications",
    "text": "3.2 Applications\nIn exploring the practical areas of this section, two major enhancement technologies that stood out to me were NDVI and PCA. In terms of NDVI, I had first heard about it and mentioned it in my learning diary in the first week, and as for PCA, I had been exposed to it in my quantitative methods course in the last term. That‚Äôs why I‚Äôm most curious about both.\n\n3.2.1 NDVI (Normalized Difference Vegetation Index)\nRatio must be mentioned when referring to NDVI.\nRatio calculation involves dividing the pixel values of one band by the corresponding pixel values of another band, which helps reduce the impacts of factors such as changes in illumination, terrain shadows, etc., thus increasing the accuracy of the analysis. NDVI is a classic example of ratio.\nNDVI assess the condition of vegetation growth by measuring the difference between near-infrared (which vegetation strongly reflects) and red light (which vegetation absorbs).\n\\[\nNDVI = \\frac{(NIR-Red)}{(NIR+Red)}\n\\] NIR represents the reflectance of the Near-Infrared band, and Red represents the reflectance of the Red band. NDVI values range from -1 to 1. High values of NDVI indicate higher levels of live green vegetation.\n\n\n\nSource: Earthobservatory.Nasa\n\n\nHow do we use NDVI? \nWe see several sectors using NDVI. For example, in agriculture, farmers use NDVI for precision farming and to measure biomass. Whereas, in forestry, foresters use NDVI to quantify forest supply and leaf area index.\nThe below graphics shows the Landsat Surface Reflectance (SR) NDVI maps of the San Joaquin Valley region of California on March 10, 2022 and March 13, 2023. The left 2022 map shows the impact on local vegetation after several years of drought. An extremely wet spring in 2023 lead to an early green-up in the valley.\n \nNDVI Maps of the San Joaquin Valley Region, March 2022 and March 2023. Source: USGS\nFurthermore, NASA states that NDVI is a good indicator of drought. When water limits vegetation growth, it has a lower relative NDVI and density of vegetation.\nThe below satellite maps of vegetation show the density of plant growth over the entire globe. Very low values of NDVI (0.1 and below) correspond to barren areas of rock, sand, or snow. Moderate values represent shrub and grassland (0.2 to 0.3), while high values indicate temperate and tropical rainforests (0.6 to 0.8).\n\n\n\nSource: Earthobservatory.Nasa\n\n\n\n\n3.2.2 PCA (Principal Component Analysis)\nI was introduced to the concept of PCA for the first time In the quantitative methods course last term. It is used to reduce the dimensionality of datasets with correlated independent variables. The result allowed me to retain most of the information in the dataset with as few principal components as possible, effectively reducing the size of the dataset while also enhancing interpretability.\nHow to use PCA in remote sensing? \nRunning a principal component analysis on three bands was useful because we found the third component did not add much information.\nWhat about a 10-band multispectral image? Or even 100 or 200 bands (hyperspectral imagery)? This is where PCA is really useful ‚Äì multispectral and hyperspectral analysis.\nFor example, if most of the variance (eigenvalue) is found in principal components one, two, and three, it‚Äôs only necessary to use these three principal components. For land cover classification, it is much easier to use three bands compared to all 100 bands. In summary, PCA identifies duplicate data over multiple channels, reduces redundancy, and speeds up the processing time. This is key for PCA image processing.\n\n\n\nInformation extraction of hypercritical data. Source: Rsgisworld"
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3¬† Week 3 - Corrections and Image Enhancements",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nReflecting on the week‚Äôs lessons in remote sensing, I‚Äôve been struck by the complexity of interpreting Earth via satellite imagery. The focus on corrections and enhancements, like geometric and atmospheric corrections, and the use of NDVI and PCA‚Äîhas deepened my understanding of the field‚Äôs precision and the technological tools at our disposal. This exploration underscored the vital balance between leveraging technology and applying human insight to fully realize the full potential of remote sensing data.\nIt may be a bit much to write about these last few weeks because there is a great deal of unfamiliar terms and concepts to understand for me, who is completely new to the remote sensing journey, and I will try to keep it as concise as possible for the rest of the week!üòÑ However, I firmly believe in the importance of establishing a strong foundation for my future in-depth practice. I also broadened my horizons by searching for information and communicating with others after class, which is very interesting and rewarding. I really enjoy exploring the unknown and enriching myself with new skills.ü•∞"
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "4¬† Week 4 - Air Pollution & Control Action in Beijing",
    "section": "4.1 Summary",
    "text": "4.1 Summary\nMy city of choice is Beijing, the capital of China. Beijing is one of the most polluted cities in the world (Maji & Lam, 2020). And its air quality improvements are a model for other cities.\n2019, a new report by the United Nations Environment Programme (UN Environment) and the Beijing Municipal Ecology and Environment Bureau (BEE) outlines how Beijing‚Äôs air quality management programme has evolved over the past quarter century, called ‚ÄúA Review of 20 Years‚Äô of Air Pollution Control in Beijing‚Äù.\n\n\n\nSource: UNEP\n\n\nIn 1998 Beijing declared war on air pollution, the challenge was to find ways to improve air quality in one of the largest and fastest growing cities in the developing world. 20 years on and it appears that Beijing is winning the battle. Air quality has improved substantially, and the lessons learned provide a roadmap for other cities tackling air pollution.\n‚ÄúThis improvement in air quality didn‚Äôt happen by accident. It was the result of an enormous investment of time, resources and political will,‚Äù said Joyce Msuya, Acting Executive Director of UN Environment. ‚ÄúUnderstanding Beijing‚Äôs air pollution story is crucial for any nation, district or municipality that wishes to follow a similar path.‚Äù"
  },
  {
    "objectID": "week4.html#applications",
    "href": "week4.html#applications",
    "title": "4¬† Week 4 - Air Pollution & Control Action in Beijing",
    "section": "4.3 Applications",
    "text": "4.3 Applications\nTo address the issue of air pollution in Beijing, especially PM2.5 pollution, a comprehensive approach involving remote sensing datasets and models has been utilized to monitor and analyze air quality with remarkable spatial and temporal accuracy. This approach is designed to offer actionable insights for the effective implementation of policies and the management of environmental health.\nThe application of satellite remote sensing technology plays a pivotal role in this strategy. It allows for the monitoring of atmospheric pollutants, such as PM2.5 and NO2, providing a detailed assessment of air quality trends over time. Through this technology, data is collected that can pinpoint the concentration levels of these pollutants, offering a dynamic view of how air quality fluctuates and identifying potential sources of pollution.\n\n\n\nAnnual mean spatial distribution of PM2.5 concentrations in China from 2000 to 2016 at 1-km spatial resolution. Source: Liang et al., 2020\n\n\nIn this regard, Guo et al.utilized MODIS satellite data for remote sensing monitoring of PM2.5 pollution in the Beijing area, capable of estimating ground-level PM2.5 concentrations. This method, by correlating MODIS‚Äôs Aerosol Optical Depth (AOD) measurements with ground-based PM2.5 observational data, enhanced the accuracy of PM2.5 estimates, making a significant contribution to understanding and managing Beijing‚Äôs air pollution issue. The research demonstrated the potential of satellite remote sensing technology in supplementing ground monitoring data and providing information on the spatial distribution and temporal variation of pollutants (2014).\n\n\n\nSeasonal distributions of annual mean Aqua AOD550 over North and East China during March 2012 to February 2013. Areas with higher AOD are shown in red or orange, indicating a higher concentration of atmospheric particulates in those regions. The wind directions and velocity are shown as orange arrows. Source: Guo et al., 2014\n\n\nAlso, Yang et al.¬†explored the spatiotemporal distributions of PM2.5 concentrations across the same region from 2013 to 2020. This study employed a two-stage statistical regression model (Linear Mixed Effects + Geographically Weighted Regression), considering various predictors including Aerosol Optical Depth (AOD) data, meteorological conditions, and land use information. The aim was to estimate daily PM2.5 distribution at a 1-km spatial resolution, analyzing long-term characteristics and trends of particulate pollution. This high-resolution data is crucial for identifying small-scale pollution hotspots and understanding the efficacy of pollution control measures over time (2022).\n\n\n\nThe distribution of the annual mean estimated PM2.5 concentrations and observed PM2.5 concentrations in the Beijing‚ÄìTianjin‚ÄìHebei region during 2013‚Äì2020 (A‚ÄìH). Source: Yang et al., 2022\n\n\nAnother notable study conducted by Ma et al.¬†utilized the Visible Infrared Imaging Radiometer Suite Day/Night Band (VIIRS/DNB) combined with a deep learning model to estimate nighttime PM2.5 concentrations in the Beijing‚ÄìTianjin‚ÄìHebei region from 2015 to 2021. This approach enabled the generation of high-resolution PM2.5 concentration maps, offering a detailed view of pollution distribution and trends over time, which could greatly aid in understanding and combating air pollution at a granular level (2023).\nFurthermore, Beijing has put in place a high resolution air pollution monitoring system that has enabled better enforcement of the cities air quality regulations. This video showcases how the system works and the benefits.\n\nThese studies exemplify the application of remote sensing and machine learning techniques in enhancing our understanding of air pollution patterns. The ability to monitor PM2.5 with high spatial and temporal resolution is a valuable asset in the fight against air pollution, providing a data-driven basis for policy decisions and interventions aimed at improving air quality in Beijing and similar urban environments."
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "4¬† Week 4 - Air Pollution & Control Action in Beijing",
    "section": "4.4 Reflection",
    "text": "4.4 Reflection\nIn conclusion, Beijing‚Äôs journey to improve air quality has not only achieved substantial reductions in pollutants like PM2.5, sulfur dioxide, and nitrogen oxides but also set a model for other cities worldwide. The collaborative efforts, stringent policies, and significant investments in air quality management have showcased a commendable balance between environmental protection and economic growth.\nHowever, strategies for combating air pollution in Beijing have been multifaceted, focusing on reducing coal consumption, expanding urban rail networks, and introducing high-density sensor-based PM2.5 monitoring networks. These actions, backed by both municipal and national support, have been crucial in reshaping Beijing‚Äôs transportation and reducing its environmental footprint. Measures include the establishment of Low Emission Zones (LEZs) and the modernization of the bus fleet. Beijing has become a global leader in electric mobility, boasting a vast number of electric buses, and has made considerable investments in air quality improvement measures.\nThese efforts reflect an enormous investment of time, resources, and political will, aimed at transforming Beijing into a cleaner, more sustainable city. The progress made by Beijing offers valuable lessons and a roadmap for other cities facing similar challenges with air pollution, demonstrating the potential benefits of comprehensive planning, public engagement, and the adoption of new technologies for environmental improvement."
  },
  {
    "objectID": "week4.html#beijings-air-quality-improvements-are-a-model-for-other-cities",
    "href": "week4.html#beijings-air-quality-improvements-are-a-model-for-other-cities",
    "title": "4¬† Week 4 -",
    "section": "Beijing‚Äôs air quality improvements are a model for other cities",
    "text": "Beijing‚Äôs air quality improvements are a model for other cities"
  },
  {
    "objectID": "week4.html#beijings-air-quality-improvements-are-a-model-for-other-cities.",
    "href": "week4.html#beijings-air-quality-improvements-are-a-model-for-other-cities.",
    "title": "4¬† Week 4 -",
    "section": "4.1 Beijing‚Äôs air quality improvements are a model for other cities.",
    "text": "4.1 Beijing‚Äôs air quality improvements are a model for other cities."
  },
  {
    "objectID": "week4.html#background",
    "href": "week4.html#background",
    "title": "4¬† Week 4 - Air Pollution & Control Action in Beijing",
    "section": "4.2 Background",
    "text": "4.2 Background\nWith rapid urbanization and industrialization over the past thirty years, China has become one of the few countries in the world with the most severe air pollution. According to 2015 Global Burden of Disease study, PM2.5 was globally ranked as the fifth mortality risk factor, responsible for about 4.2 million deaths and 103.1 million years of life lost or lived with disability (Duke University, 2020). The impact of air pollution on atmospheric visibility, human health, and global climate change has garnered widespread public concern.\n\n\n\nSource: Zhang et al., 2016\n\n\nIn response to these challenges, the Beijing Municipal Government (BMG) has implemented a series of control policies, laws, and regulations since 1998, with a focus on controlling SO2 and Total Suspended Particulates (TSP). However, severe haze weather still occurs, especially during the heating season (autumn and winter) (Li et al., 2020). Particularly in January 2013, severe haze enveloped Beijing and the North China region, affecting over 800 million people (Liu et al., 2020).\nSince then, starting in 2013, China has initiated unprecedented air quality improvement actions nationwide, especially targeting the management of fine particulate matter (PM2.5) pollution. The State Council of China issued the ‚ÄúAir Pollution Prevention and Control Action Plan‚Äù (APPCAP) on September 10, 2013, marking the first time China adopted a targeted national strategy aimed at improving air quality and set clear quantitative goals, such as requiring Beijing to control PM2.5 concentration to below 60Œºg/m¬≥ by 2017. To achieve this goal, the Beijing Municipal Government followed up with the ‚ÄúBeijing 2013-2017 Clean Air Action Plan‚Äù (Clean Air Action), implementing a series of stringent control measures.\n\n\n\nA bike user braving polluted air in Beijing. Source: Sustainablemobility\n\n\nHowever, the winter of 2016 still saw frequent heavy pollution days. To meet the five-year target, the ‚Äú2017-2018 Autumn and Winter Comprehensive Air Pollution Control Action Plan for the Beijing-Tianjin-Hebei Region‚Äù (hereinafter referred to as the ‚ÄúComprehensive Action‚Äù) was subsequently implemented in the autumn of 2017. Finally, by the end of 2017, Beijing‚Äôs annual average PM2.5 concentration successfully dropped to 58Œºg/m¬≥, achieving the five-year goal of the Clean Air Action.\nThe journey towards cleaner air continued with the introduction of the three-year Blue Sky Defense Plan spanning from 2018 to 2020. This subsequent phase of environmental policy and action further accelerated improvements in air quality across Beijing, with PM2.5 annual average concentrations witnessing a steady decline to 42Œºg/m¬≥ by 2019. Such progress is indicative of Beijing‚Äôs ongoing commitment to enhancing its air quality, marking significant strides in the city‚Äôs environmental health landscape (Li et al., 2020).\n\n\n\nBeijing‚Äôs Bird‚Äôs Nest in the haze and after the success of air control. Source: CCAC\n\n\nBeijing‚Äôs air quality management efforts are closely aligned with the United Nations Sustainable Development Goals (SDGs), specifically Goal 11 (to make cities and human settlements inclusive, safe, resilient, and sustainable) and Goal 13 (to take urgent action to combat climate change and its impacts). By improving air quality, Beijing not only enhances the health and quality of life of its residents but also contributes to the global fight against climate change."
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "5¬† Week 5 - Introduction to GEE",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nThis week I stepped into a whole new world, GEE (Google Earth Engine), which is a cloud-based platform that delivers a multi-petabyte catalog of satellite imagery for planetary-scale analysis.\nIt‚Äôs an incredible resource for anyone who wants to explore the world through satellite imagery.\nWe can not only gain access to remote sensing data from satellites, airborne, digital elevation models, but also we can turn this geospatial data into actionable insights through the platform‚Äôs fast computations and 1000+ types of operators for analysis.\nAnd the most important is that it‚Äôs completely free!!!\nFrom land use to weather data, it‚Äôs through its vast (and growing) catalog of remote sensing data that we can see the world through a different lens. We can have access to many key datasets on this platform, such as Landsat (30m), Sentinel-2 (10-30m), MODIS (250m daily), Sentinel-1 (Radar), Land cover, Weather and Climate (NOAA) and so on.\n\n\n\nSurface water change visualization enabled by Google Earth Engine (Aral Sea from 1984-2020). Source: GOOGLE EARTH\n\n\nLet‚Äôs step into the world of GEE and see how amazing it is!\n\n5.1.1 What Can Google Earth Engine Do?\nGEE tackles the challenge of open analysis in remote sensing with a focus on getting results. It‚Äôs able to avoid any bottlenecks because it‚Äôs able to adjust the size of its clusters based on how much demand there is for a data product.\n\n\n\n\n\n\n\nFunctionality\nDescription\n\n\n\n\nDownloading an Image\npick an extent, projection, data type, band, date, and resolution\n\n\nPerforming Library Functions\nchain algorithms together for further analysis such as a band combination function\n\n\nFiltering a Collection\nuse the metadata to filter everything from the amount of cloud cover to the type of sensor\n\n\nMapping an Algorithm to an Image Collection\napply it to a full collection like the entire United States with a batch computation instead of applying an algorithm to a single image\n\n\nComputing Aggregate Statistics\ncalculate the amount of area within an extent to check if it meets certain criteria\n\n\nBuilding Tabular Reports\ncreate tabular reports to show specific information in a table format such as summarizing a detailed list of data, highlighting specific metrics, or showing comparisons between different sets of data\n\n\n\n\n\n5.1.2 Geospatial Processing Functions\nGEE contains more than 1000 data types and operators to help lay a solid foundation for any type of remote sensing analysis.\n\nIn addition to these analysis tools, there are other specialty types of algorithms. For instance, cloud and shadow filtering algorithms help remove artifacts so we can focus your analysis on the Earth‚Äôs surface.\nBut one of the most exciting areas of development in GEE is a shift to machine learning algorithms and deep neural networks. For example, (1) SVM (2) Random forests (3) K-Means (4) CART\n\n\n5.1.3 How to get started?\nIsn‚Äôt it amazing and powerful! I can‚Äôt wait to operate it after hearing all this. If you want to learn how to do it, but are a complete beginner like me, I found the video below very helpful."
  },
  {
    "objectID": "week5.html#applications",
    "href": "week5.html#applications",
    "title": "5¬† Week 5 - Introduction to GEE",
    "section": "5.2 Applications",
    "text": "5.2 Applications\n\n5.2.1 GEE Web Application Examples\nOn GEE‚Äôs homepage we can see that there are six curated applications, from time-lapse imagery to global forest change web maps. Each one demonstrates its powerful computing and how it can lead to making informed decisions for the environment.\n\nOcean Timelapse: one of the most powerful features of GEE is its vast amount of temporal data. With over 35+ years of imagery, it‚Äôs like we‚Äôre traveling back in time on an interactive map of the ocean.\nLinked Maps: shows separate viewports with different band combinations. While the natural color is similar to what the human eye sees, the color-infrared, Land/Water, and Vegetation viewport highlights other land use features.\nSplit Panel: contains a slider with two separate images side-by-side. We can compare two images from different dates beside each other to easily check for the differences between them.\nCollection Mosaic: allows us to select from a group of Landsat-8 images, and based on it, the app will generate a mosaic using the median values.\nGlobal Population Explorer: after selecting a country, it dynamically creates a graph or table with the population density of that country.\nGlobal Forest Change: shows the results of global forest change using Landsat imagery between 2000 and 2016. We can interactively pan and zoom around in app and can symbolize deforestation based on the year of the loss or by the percent of tree cover.\n\n \nSource:Google Earth Engine\n\n\n5.2.2 Monitor Global Forest Changes\nThe most impressive application of GEE to me is illegal deforestation in Brazil. The teacher mentioned this very interesting case in the first week class, which aroused my great interest in GEE at that time.\nForests are critical ecosystems for fighting climate change, supporting livelihoods and protecting biodiversity.\nDue to its vast forest resources, Brazil has always been targeted by international and domestic loggers, leading to massive human-induced destruction of the Amazon rainforest. In the past, illegal loggers took advantage of the limitations of technology and monitoring to avoid detection and prosecution. They carefully planned to cut down areas smaller than one square kilometer to escape monitoring at the kilometer resolution.\n\n\n\nSpatial mapping of forest degradation in Brazilian Amazon forest ecosystems. Source: Matricardi et al., 2020\n\n\nHowever, the emergence of GEE changed all. To create the global forest map, GEE used a network of cloud-based servers to process 650,000 images across 10,000 computers working in parallel. It would have taken a solo computer 15 years to do the job.\nGEE‚Äôs 30-meter high resolution ensures that even the smallest environmental changes are detectable, greatly increasing the ability to detect illegal logging activities. As a result, about 100 lawsuits due to illegal logging were filed in just one year, compared to almost none in the previous 20 years.\nNow, with the application below, we can easily access the global forest map, monitor forest changes in real time, and effectively expose and combat illegal logging activities.\n\n\n\n\n\n\n\n5.2.3 Monitor Natural Disaster\nThe UNI-Spider Knowledge Portal platform has been using the GEE as a tool to try to analyse and mitigate natural disasters. They use Sentinel-1 SAR data from Google Earth Engine for flood mapping and damage assessment, which is used to provide a comprehensive overview of flooding from small communities to countries (UNOOSA/UN-SPIDER, 2020). In addition to the outline of flood areas, this code produces information about farmland affected to better plan for food security concerns after a disaster and the number of families that have been or could be affected by natural disasters.\n\n\n\nFlood mapping. Source: Chiefscient\n\n\n\n\n5.2.4 Building Footprints\nI have to mention this because it is closely related to the topic of my dissertation. A building footprint dataset contains the two dimensional outlines of buildings in a given area. Currently, GEE hosts one building footprint dataset which covers all of Africa. In 2022, Microsoft released a free global building footprint dataset, though to use it in Earth Engine we have to download it from their GitHub page and upload it manually to GEE. The same goes for OpenStreetMap (OSM), a public database of building footprints, roads, and other features that also contains useful annotations for many buildings indicating their use. The following great video teaches us how to map anything with freely available location data (OSM data)."
  },
  {
    "objectID": "week5.html#reflection",
    "href": "week5.html#reflection",
    "title": "5¬† Week 5 - Introduction to GEE",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nThis week, the introduction to Google Earth Engine (GEE) was a revelation, showcasing the staggering advancement in technology and data analytics is changing our lives and the world, also providing innovative means to solve some long-standing issues.\nInitially, I, who first came into the coding world last semester and only learned R and Python, was apprehensive about using JavaScriptüòü. However, thanks to the plethora of tutorials available, now I found the required scripting are manageable. Its user-friendly nature and the direct access to analysis-ready data significantly enhanced my learning experience. Adapting to Earth Engine‚Äôs quirks‚Äîsuch as the inability to run code blocks independently, necessitating the execution of the entire script each time‚Äîwas part of the learning curve.\nAfter this week, I have found it really enjoyable to interact with GEE, its ability and speed to process large amounts of data (compared to what we have previously used with SNAP and R) is amazing and has revolutionised the way we approach and solve critical environmental problems. My current biggest hope is that such cool software will remain free, and I eagerly look forward to exploring the rest of it in depthü§©."
  }
]